{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "557eedba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn general, multithreading is preferable for tasks that involve I/O-bound operations, such as reading/writing \\nfiles, handling network requests, or interacting with databases, because it allows concurrent execution without\\nmuch CPU overhead. Since these tasks often involve waiting for external resources, threads can efficiently overlap\\nI/O activities while one waits, allowing another to proceed.\\n\\nMultiprocessing is ideal for CPU-bound tasks, like heavy computations, data processing, or image manipulation, \\nwhich require substantial CPU usage. Each process has its own memory space, avoiding the Global Interpreter Lock\\n(GIL) in Python, which can limit the effectiveness of threads in CPU-intensive scenarios.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\n",
    "# multiprocessing is a better choice.\n",
    "\n",
    "'''\n",
    "In general, multithreading is preferable for tasks that involve I/O-bound operations, such as reading/writing \n",
    "files, handling network requests, or interacting with databases, because it allows concurrent execution without\n",
    "much CPU overhead. Since these tasks often involve waiting for external resources, threads can efficiently overlap\n",
    "I/O activities while one waits, allowing another to proceed.\n",
    "\n",
    "Multiprocessing is ideal for CPU-bound tasks, like heavy computations, data processing, or image manipulation, \n",
    "which require substantial CPU usage. Each process has its own memory space, avoiding the Global Interpreter Lock\n",
    "(GIL) in Python, which can limit the effectiveness of threads in CPU-intensive scenarios.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee9e32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA process pool is a collection of worker processes that are managed together to execute tasks concurrently, \\noften used in multiprocessing. It helps manage multiple processes efficiently by reusing a fixed number of \\nprocesses to handle a larger number of tasks, reducing the overhead of creating and destroying processes \\nrepeatedly. This makes it highly efficient for parallel execution of repetitive, CPU-bound tasks, as tasks can \\nbe distributed across the pool. The pool also allows easy task management, scheduling, and tracking of completed \\ntasks.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
    "\n",
    "'''\n",
    "A process pool is a collection of worker processes that are managed together to execute tasks concurrently, \n",
    "often used in multiprocessing. It helps manage multiple processes efficiently by reusing a fixed number of \n",
    "processes to handle a larger number of tasks, reducing the overhead of creating and destroying processes \n",
    "repeatedly. This makes it highly efficient for parallel execution of repetitive, CPU-bound tasks, as tasks can \n",
    "be distributed across the pool. The pool also allows easy task management, scheduling, and tracking of completed \n",
    "tasks.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c84069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMultiprocessing in Python is a technique for running multiple processes in parallel, typically across multiple \\nCPU cores, which allows a program to execute CPU-bound tasks more efficiently. Each process runs in its own memory \\nspace, avoiding the Global Interpreter Lock (GIL) limitations in Python, which restricts concurrent execution \\nwithin a single process. Multiprocessing is particularly beneficial for tasks requiring intensive computation,\\nlike data processing, numerical simulations, or machine learning, where multiple processes can improve performance\\nby distributing the workload across available CPU cores.\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.Explain what multiprocessing is and why it is used in Python programs.\n",
    "'''\n",
    "Multiprocessing in Python is a technique for running multiple processes in parallel, typically across multiple \n",
    "CPU cores, which allows a program to execute CPU-bound tasks more efficiently. Each process runs in its own memory \n",
    "space, avoiding the Global Interpreter Lock (GIL) limitations in Python, which restricts concurrent execution \n",
    "within a single process. Multiprocessing is particularly beneficial for tasks requiring intensive computation,\n",
    "like data processing, numerical simulations, or machine learning, where multiple processes can improve performance\n",
    "by distributing the workload across available CPU cores.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42690c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: 24 | List: [24]\n",
      "Removed: 24 | List: []\n",
      "Added: 99 | List: [99]\n",
      "Removed: 99 | List: []\n",
      "Added: 43 | List: [43]\n",
      "Added: 71 | List: [43, 71]\n",
      "Removed: 43 | List: [71]\n",
      "Added: 62 | List: [71, 62]\n",
      "Removed: 71 | List: [62]\n",
      "Added: 52 | List: [62, 52]\n",
      "Added: 88 | List: [62, 52, 88]\n",
      "Removed: 62 | List: [52, 88]\n",
      "Added: 30 | List: [52, 88, 30]\n",
      "Removed: 52 | List: [88, 30]\n",
      "Added: 96 | List: [88, 30, 96]\n",
      "Added: 45 | List: [88, 30, 96, 45]\n",
      "Removed: 88 | List: [30, 96, 45]\n",
      "Removed: 30 | List: [96, 45]\n",
      "Removed: 96 | List: [45]\n",
      "Removed: 45 | List: []\n"
     ]
    }
   ],
   "source": [
    "# 4.Write a Python program using multithreading where one thread adds numbers to a list, and another thread \n",
    "# removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.\n",
    "\n",
    "import threading\n",
    "import time\n",
    "import random\n",
    "numbers = []\n",
    "lock = threading.Lock()\n",
    "def add_numbers():\n",
    "    for _ in range(10):\n",
    "        with lock: \n",
    "            num = random.randint(1, 100)\n",
    "            numbers.append(num)\n",
    "            print(f\"Added: {num} | List: {numbers}\")\n",
    "        time.sleep(0.1)  \n",
    "def remove_numbers():\n",
    "    for _ in range(10):\n",
    "        with lock:  \n",
    "            if numbers:\n",
    "                num = numbers.pop(0)\n",
    "                print(f\"Removed: {num} | List: {numbers}\")\n",
    "        time.sleep(0.15)  # Simulate processing time\n",
    "t1 = threading.Thread(target=add_numbers)\n",
    "t2 = threading.Thread(target=remove_numbers)\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()\n",
    "# output:\n",
    "# Added: 24 | List: [24]\n",
    "# Removed: 24 | List: []\n",
    "# Added: 99 | List: [99]\n",
    "# Removed: 99 | List: []\n",
    "# Added: 43 | List: [43]\n",
    "# Added: 71 | List: [43, 71]\n",
    "# Removed: 43 | List: [71]\n",
    "# Added: 62 | List: [71, 62]\n",
    "# Removed: 71 | List: [62]\n",
    "# Added: 52 | List: [62, 52]\n",
    "# Added: 88 | List: [62, 52, 88]\n",
    "# Removed: 62 | List: [52, 88]\n",
    "# Added: 30 | List: [52, 88, 30]\n",
    "# Removed: 52 | List: [88, 30]\n",
    "# Added: 96 | List: [88, 30, 96]\n",
    "# Added: 45 | List: [88, 30, 96, 45]\n",
    "# Removed: 88 | List: [30, 96, 45]\n",
    "# Removed: 30 | List: [96, 45]\n",
    "# Removed: 96 | List: [45]\n",
    "# Removed: 45 | List: []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a63058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPython offers several tools and methods for safely sharing data between threads and processes:\\n\\nFor Threads:\\nthreading.Lock->A basic lock to prevent simultaneous access to shared data by multiple threads, helping avoid race \\nconditions.\\nthreading.RLock->A reentrant lock that allows the same thread to acquire the lock multiple times, useful in \\nrecursive functions.\\nthreading.Event->A signaling mechanism for threads to wait until an event is set, allowing coordination between \\nthreads.\\n\\nFor Processes:\\nmultiprocessing.Queue->A thread- and process-safe FIFO queue that allows processes to share data.\\nmultiprocessing.Value and Array->Provides shared memory objects (Value for single values, Array for arrays) between\\nprocesses.\\nmultiprocessing.Manager->Creates a manager object that can manage shared data structures like lists and \\ndictionaries among processes.\\nmultiprocessing.Pipe->acilitates communication between two processes with a bidirectional channel.\\n\\nThese tools ensure safe and efficient data sharing across threads and processes, supporting parallel execution \\nwhile avoiding conflicts.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.Describe the methods and tools available in Python for safely sharing data between threads and processes.\n",
    "'''\n",
    "Python offers several tools and methods for safely sharing data between threads and processes:\n",
    "\n",
    "For Threads:\n",
    "threading.Lock->A basic lock to prevent simultaneous access to shared data by multiple threads, helping avoid race \n",
    "conditions.\n",
    "threading.RLock->A reentrant lock that allows the same thread to acquire the lock multiple times, useful in \n",
    "recursive functions.\n",
    "threading.Event->A signaling mechanism for threads to wait until an event is set, allowing coordination between \n",
    "threads.\n",
    "\n",
    "For Processes:\n",
    "multiprocessing.Queue->A thread- and process-safe FIFO queue that allows processes to share data.\n",
    "multiprocessing.Value and Array->Provides shared memory objects (Value for single values, Array for arrays) between\n",
    "processes.\n",
    "multiprocessing.Manager->Creates a manager object that can manage shared data structures like lists and \n",
    "dictionaries among processes.\n",
    "multiprocessing.Pipe->acilitates communication between two processes with a bidirectional channel.\n",
    "\n",
    "These tools ensure safe and efficient data sharing across threads and processes, supporting parallel execution \n",
    "while avoiding conflicts.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52153464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHandling exceptions in concurrent programs is crucial for preventing unanticipated crashes, resource leaks, and \\ninconsistent states across threads or processes. If one thread or process encounters an error, it can compromise \\nthe stability of the entire program or leave shared resources in a bad state, especially if unmanaged.\\n\\nTechniques for Handling Exceptions in Concurrency:\\n1)try-except Blocks->Wrapping each thread/process task in a try-except block to catch and handle errors \\nindividually.\\n2)Thread/Process-Specific Logging->Use logging inside each thread or process to track exceptions and issues in \\nreal-time.\\n3)Threading and Multiprocessing Libraries->Python’s concurrent.futures provides ThreadPoolExecutor and \\nProcessPoolExecutor with submit() or map() methods that allow catching exceptions as they occur, making it easier \\nto manage in asynchronous tasks.\\n4)Timeouts and Retry Logic->Adding timeouts and retry mechanisms within tasks helps mitigate transient errors that \\ncould otherwise halt execution.\\n\\nProper exception handling enhances resilience and improves error traceability in concurrent systems.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.Discuss why it's crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n",
    "'''\n",
    "Handling exceptions in concurrent programs is crucial for preventing unanticipated crashes, resource leaks, and \n",
    "inconsistent states across threads or processes. If one thread or process encounters an error, it can compromise \n",
    "the stability of the entire program or leave shared resources in a bad state, especially if unmanaged.\n",
    "\n",
    "Techniques for Handling Exceptions in Concurrency:\n",
    "1)try-except Blocks->Wrapping each thread/process task in a try-except block to catch and handle errors \n",
    "individually.\n",
    "2)Thread/Process-Specific Logging->Use logging inside each thread or process to track exceptions and issues in \n",
    "real-time.\n",
    "3)Threading and Multiprocessing Libraries->Python’s concurrent.futures provides ThreadPoolExecutor and \n",
    "ProcessPoolExecutor with submit() or map() methods that allow catching exceptions as they occur, making it easier \n",
    "to manage in asynchronous tasks.\n",
    "4)Timeouts and Retry Logic->Adding timeouts and retry mechanisms within tasks helps mitigate transient errors that \n",
    "could otherwise halt execution.\n",
    "\n",
    "Proper exception handling enhances resilience and improves error traceability in concurrent systems.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c044e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. \n",
    "# Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
    "\n",
    "import concurrent.futures\n",
    "import math\n",
    "def factorial(n):\n",
    "    return math.factorial(n)\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = {executor.submit(factorial, i): i for i in range(1, 11)}\n",
    "    for future in concurrent.futures.as_completed(results):\n",
    "        number = results[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            print(f\"Factorial of {number} is {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating factorial for {number}: {e}\")\n",
    "\n",
    "# output:\n",
    "# Factorial of 9 is 362880\n",
    "# Factorial of 8 is 40320\n",
    "# Factorial of 7 is 5040\n",
    "# Factorial of 2 is 2\n",
    "# Factorial of 1 is 1\n",
    "# Factorial of 6 is 720\n",
    "# Factorial of 4 is 24\n",
    "# Factorial of 5 is 120\n",
    "# Factorial of 3 is 6\n",
    "# Factorial of 10 is 3628800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878780ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in \n",
    "# parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 \n",
    "# processes)\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Function to calculate square\n",
    "def square(n):\n",
    "    return n * n\n",
    "\n",
    "# Measure execution time with different pool sizes\n",
    "def measure_time(pool_size):\n",
    "    numbers = list(range(1, 11))\n",
    "    with multiprocessing.Pool(pool_size) as pool:\n",
    "        start_time = time.time()\n",
    "        results = pool.map(square, numbers)\n",
    "        end_time = time.time()\n",
    "    print(f\"Pool size {pool_size}: Results {results}, Time taken: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test with different pool sizes\n",
    "    for size in [2, 4, 8]:\n",
    "        measure_time(size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ad1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e003f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
